---
title: "README"
output: github_document
---
# INTRO

This is the README file for Nathan Potgieter's financial econometrics project. 

## Aim
The aim of this project is to develop a general and easy to use Monte Carlo package that generates asset return data with a prespecified correlation structure and dynamic dependencies. The user will be able to adjust a "leverage" parameter, which determines the likelihood of entering a "crisis period" characterized by extreme joint drawdowns. The data will also be generated to exhibit  ARIMA(p,q) + GARCH(q,p) features, the parameters of which can be adjusted to induce alternative forms of risk. Elliptical copulas are used to induce the correlation in the simulated data, while Archmedian copulas are used to adjust the likelihood of joint drawdowns. Various ARIMA(p,q) + GARCH(q,p) structures can be called on to induce mean and variance persistence.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(tidyverse, copula)

```

# Generating Covarience matrix

In this section I developed a simple function that allows the user to easily generate a covarience matrix with the desired cluster structure. Note that the majority of the code was writen by Nico Katzke. The function is located in the gcVar.R code file. 

### gcVar's arguments 

1. N - is the number of assets in the universe

2. Clusters - a character string specifying the type of cluster structure. Available options are "none", for a correlation matrix with no clusters, "non-overlapping" for a correlation matrix with number one layer of clusters, and "overlapping" for a correlation  matrix with Num_Layers and Num_clusters per layer.

3. Num_Clusters - if Clusters is equal to "non-overlapping" or "none" then Num_Clusters is an integer value specifying the number of clusters. If Clusters = "overlapping" then Num_Clusters must be a vector of length equal to Num_Layers specifying the number of clusters per layer. 

4. Num_Layers - an integer value between 1 and 4, specifying the number of cluster layers. Only needed of using "overlapping" clusters. 


```{r gcVar}
#Co-Varience matrix generatimg function

gcVar <- 
  function(N = 50, Clusters = c("none", "non-overlapping", "overlapping") , Num_Clusters = NULL, Num_Layers = NULL){
    
Grps <- Num_Clusters
#set.seed(123)
    
if(Clusters == "none"){
    # Unclustered covariance matrix
    Sigma <- diag(N)
    for (i in 1:N) for (j in 1:N) Sigma[i,j] <- 0.9^abs(i-j)
    Sigma <- propagate::cor2cov(Sigma, runif(N, 1, 5))
    corr <- cov2cor(Sigma)
} else

if(Clusters == "non-overlapping"){
    #----------------------
    # distinct non-overlapping clusters:
    #----------------------
    
    if(is.null(Num_Clusters)) stop("Please provide a valid Num_Clusters argument when using Overlapping clusters")
    
    
    Sigma <- matrix(0.9, N, N)
    diag(Sigma) <- 1

    
for (i in 1:Grps) {
      ix <- seq((i-1) * N / Grps + 1, i * N / Grps)
      Sigma[ix, -ix] <- 0.0001                       #think about
    }
    Sigma <- propagate::cor2cov(Sigma, runif(N, 1, 5))
    corr <- cov2cor(Sigma)
} else
  
if(Clusters == "overlapping"){
    #----------------------
    # distinct overlapping clusters:
    #----------------------
  
  if(is.null(Num_Layers)|Num_Layers<2){
      stop("Please provide a valid Num_Layers argument when using Overlapping clusters")
      }else
  if(length(Num_Clusters) != Num_Layers){
      stop("Please provide a Num_Clusters argument with length equal to Num_Layers")
  }
    
  
    Sigma <- matrix(0.9, N, N)
    diag(Sigma) <- 1

    for (i in 1:Grps[1]) {
      ix <- seq((i-1) * N / Grps[1] + 1, i * N / Grps[1])
      Sigma[ix, -ix] <- 0.7
    }
    
    if(Num_Layers>=2){
        for (i in 1:Grps[2]) {
          ix <- seq((i-1) * N / Grps[2] + 1, i * N / Grps[2])
          Sigma[ix, -ix] <- 0.05
        } }else
    if(Num_Layers>=3){
        for (i in 1:Grps[3]) {
      ix <- seq((i-1) * N / Grps[3] + 1, i * N / Grps[3])
      Sigma[ix, -ix] <- 0.03
        } }else
    if(Num_Layers>=4){
        for (i in 1:Grps[4]) {
      ix <- seq((i-1) * N / Grps[4] + 1, i * N / Grps[4])
      Sigma[ix, -ix] <- 0
        } } 
    }

    Sigma <- propagate::cor2cov(Sigma, runif(N, 1, 5))  #Is this necessary???
    corr <- cov2cor(Sigma)

return(corr)

  }

```

Demonstrating the use of gcVar
```{r using gcVar, fig.show='hide', include=FALSE}

gcVar(N = 50, Clusters = "none") %>% corrplot::corrplot()
gcVar(N = 50, Clusters = "non-overlapping", Num_Clusters = 2) %>% corrplot::corrplot()
gcVar(N = 60, Clusters = "overlapping", Num_Layers = 2, Num_Clusters = c(10,5)) %>% corrplot::corrplot()

```

## GeneratingRrandom Draws with numerous Copula Functions

### Elliptal copulas

Elliptal copulas such as the Gaussian and the student t copulas, allow us to specify a correlation matrix as a parameter. Doing so allows one to produce random draws of uniformly distributed variables, that contain the correlation structure and joint distribution specified by the copula. The chunk of code below demonstrates this functionality. 

Unfortunately, both Elliptal copulas cannot be calibrated to exhibit increased co-movements within the tails of the distribution. Therefore, in the next section we examine some properties of Archimedean copulas. 


```{r Elliptal Copulas, fig.show='hide', include=FALSE}
#loading copula package
pacman::p_load(copula)

#generating corr  matrix object
corr <- gcVar(N = 50, Clusters = "overlapping", Num_Layers = 3, Num_Clusters = c(10, 5, 2))

#generating copula objects   
Ncop <- ellipCopula(family = "normal", dispstr = "un", param = P2p(corr), dim = 50)
Tcop <- ellipCopula(family = "t", dispstr = "un", param = P2p(corr), dim = 50)

#generating 251 random draws for each of the N variables
set.seed(123)
rn <- rCopula(copula = Ncop, n = 100)
rt <- rCopula(copula = Tcop, n = 100)

#Checking if the correlation structure was maintained
# Origional corr
corr %>% corrplot::corrplot()
# corr from random draws form norm and t copula
cor(rn) %>% corrplot::corrplot()
cor(rt) %>% corrplot::corrplot()

#Notice that the underlying correlation structure has been maintained for the most part

```

### Archimedean copulas

Archimedean copulas such as the clayton, frank, gumbel and joe exhibit increased dependence at the tails of the multivariate distribution. In this section we will examine the clayton, .... copulas due to them  exhibiting enhanced left-tail dependencies. We will also have a look at the hybrid BB1-BB6 which in which exibit increased dynamic dependenies in both tails. 

```{r arch copulas, fig.show='hide', include=FALSE}
# first look at at dim=2 to get understanding of what parameter tning does

#Clayton Copula
claycop <- archmCopula(family = "clayton", param = 4, dim = 2)
# rCopula(251, claycop)

#note how left tail dependence increases with the parameter
persp(claycop, dCopula, zlim = c(0, 25))
rCopula(1000, copula = claycop) %>% plot()

#Note that the Gumbel and Joe copulas must be rotated 180 degrees to exhibit greater left tail dependence
#Gumbel Copula
gumcop <- archmCopula(family = "gumbel", param = 4, dim = 2) %>% rotCopula()

#note how right tail dependence > left tail dependence; tail dependence increase with the parameter value.
persp(gumcop, dCopula, zlim = c(0, 10))
rCopula(1000, copula = gumcop) %>% plot()

#Joe copula
joecop <- archmCopula(family = "joe", param = 3, dim = 2) %>% rotCopula()

#note how right tail dependence > left tail dependence;tail dependence increase with the parameter value at rate < gumbel
persp(joecop, dCopula, zlim = c(0, 10))
rCopula(1000, copula = joecop) %>% plot()


#looking at some hybrid copulas
#Galambos
galcop <- evCopula(family = "galambos", param = 2, dim = 2) %>% rotCopula()

persp(galcop, dCopula, zlim = c(0, 10))
rCopula(1000, galcop) %>% plot()

```

# Looking at some hybrid copulas

Tawn's (1988) Theorem: Shows that a copula is a convex set and every convex combination of existing copula functions is again a copula. See "Extreme Dependence Structures and the Cross-Section of Expected Stock Returns" page 8 & 9. 


```{r hybrid, include=FALSE, fig.show='hide'}
#first lookat at situation when dim = 2

#Elliptical  Copulas
Ncop <- ellipCopula(family = "normal", dispstr = "un", param = 0.8, dim = 2)
Tcop <- ellipCopula(family = "t", dispstr = "un", param = 0.8, dim = 2, df = 1)

#left tail dependence copulas
claycop <- archmCopula(family = "clayton", param = 2, dim = 2)
#the following dont work for high dimentions
gumcop <- archmCopula(family = "gumbel", param = 3, dim = 2) %>% rotCopula() 
joecop <- archmCopula(family = "joe", param = 3, dim = 2) %>% rotCopula()
galcop <- evCopula(family = "galambos", param = 2, dim = 2) %>% rotCopula()


#looking at different combinations
set.seed(123)
w1 <-  0.5  #tinker with weights and notice what happens; observed corr diminishes as we decrease w1

#Norm + Clayton
data <- (1-w1)*rCopula(10000, Ncop) + w1*rCopula(10000, claycop)
cor(data)
plot(data, type = "p")

#T + Clayton; try adjusting the df to see what happens
data <- (1-w1)*rCopula(10000, Tcop) + w1*rCopula(10000, claycop)
cor(data)
plot(data, type = "p")

#T + Gumbel; rotated Gumbel cop exhibits more right-tail dependence than Clayton, therefore may be better to pair with Normcop?
data <- (1-w1)*rCopula(10000, Tcop) + w1*rCopula(10000, gumcop)
cor(data)
plot(data, type = "p")

#Norm + Gumbel
data <- (1-w1)*rCopula(10000, Ncop) + w1*rCopula(10000, gumcop)
cor(data)
plot(data, type = "p")
#the gumbel copula maintains the correlation better than the clayton


```

## hycop

The function below generates randomly distributed numbers from a hybrid t and clayton copula.
Need to think about how to calibrate df and claycop parameters. 

Arguments

- Corr this is a correlation matrix uses as the parameter for the elliptical copula
- elliptal_copula family name of elliptal copula. Default is to use "t", but "norm" is also accepted
- df_ellip a positive integer specifying the degrees of freedom for the student t elliptic copula. Only required when using elliptal_copula = "t".
- left_cop_param a positive integer specifying the parameter of the __Clayton__ copula. 
- left_cop_weight a value between 0 and 1 corresponding to the weight assigned to the left copula, when generating random draws from a hybrid copula.
- marginal_dist a character string specifying the marginal distribution of the simulated data. Must be "norm" or "t", with the default generating uniformly distributed marginals.
- df_marginal_dist a positive integer specifying the degrees of freedom parameter of the "t" distributed marginals. 


```{r hycop function}

hycop <- function(corr,
                  elliptal_copula = c("norm", "t"), 
                  df_ellip = NULL, 
                  left_cop_param = 5,
                  left_cop_weight = 0.5,
                  T = 251, 
                  marginal_dist = NULL,
                  df_marginal_dist = NULL){
  
  N <- nrow(corr)  
  Cor <- P2p(corr)

#specifying  Copula's
#elliptal
  if(elliptal_copula == "t"){
    
    if(is.null(df_ellip))stop('Please supply a valid degrees of freedom parameter when using elliptal_copula = "t". ')
    Ecop <- ellipCopula(family = elliptal_copula, dispstr = "un", df = df_ellip, param = Cor, dim = N)
    
  }else
    if(elliptal_copula == "norm"){
      
       Ecop <- ellipCopula(family = "norm", dispstr = "un", param = Cor, dim = N)
      
    }else stop("Please supply a valid argument for elliptal_copula")
   

#left-cop
  
    Acop <- archmCopula(family = "clayton", param = left_cop_param, dim = N)
    
 
    
  

data <- left_cop_weight*rCopula(T, Acop) + (1-left_cop_weight)*rCopula(T, Ecop)


#Converting Uniform marginal distributions to t or norm
if(is.null(marginal_dist)==TRUE){
  return(data)
      }else
        if(marginal_dist=="t"){
          
          if(is.null(df_marginal_dist))stop('Please supply a valid degrees of freedom parameter (df_marginal_dist) when using marginal_dist=="t". ')
          
          data <- apply(data, 2, qt, df = df_marginal_dist)
          
        }else
          if(marginal_dist=="norm"){
            data <- apply(data, 2, qnorm)
            }
            
}

```

Testing hycop

```{r}
set.seed(123)

Corr <- gcVar(N = 50, Clusters = "overlapping", Num_Layers = 3, Num_Clusters = c(10,5,2))
Corr %>% corrplot::corrplot()

#First test when marginal_dist=NULL ie unif(0,1)
#left_cop_param = 6 AND left_cop_weight = 0.7 looks good
set.seed(123)
inno <- hycop(Corr, elliptal_copula = "t", df_ellip = 10, left_cop_param = 10, left_cop_weight = 0.4, T = 10000)

inno %>% plot(main = 'Hycop: Unif marginals')
inno %>% cor %>%  corrplot::corrplot()

#Using marginal_dist="norm"
set.seed(123)
data <- hycop(Corr, elliptal_copula = "t", df_ellip = 30, left_cop_param = 10, left_cop_weight = 0.5, T = 10000, marginal_dist = "norm")
data %>% plot(main = 'Hycop: norm(0,1) marginals') 
data %>% cor %>%  corrplot::corrplot()

#Using marginal_dist="t"
set.seed(123)
data <- hycop(Corr, elliptal_copula = "t", df_ellip = 10, left_cop_param = 6, left_cop_weight = 0.5, T = 10000, marginal_dist = "t", df_marginal_dist = 8)
data %>% plot(main = 'Hycop: t-dist marginals, df = 8') 
plot(data[,1], data[,10], main = 'Hycop: t-dist marginals, df = 8')
plot(data[,1], data[,ncol(data)], main = 'Hycop: t-dist marginals, df = 8')
data %>% cor %>%  corrplot::corrplot()

```


# Introducing autocorrelation and Volitility clustering

In this step I introduce autocorrelation and volatility using an AR(p,q)+GARCH(q,p) model. 

## Questions 

- How should I deal with the burn in period?


```{r}
pacman::p_load(fGarch)

#Looking at garchSpec function
garch <- fGarch::garchSpec(model = list(ar = 0.1, alpha = 0.1, beta = 0.75, gamma = 0.1), 
                           cond.dist = "norm", presample = NULL)

function (model = list(), presample = NULL, cond.dist = c("norm", 
    "ged", "std", "snorm", "sged", "sstd"), 
    rseed = NULL) 
{
  #default for innovation distribution
    cond.dist = match.arg(cond.dist)
    skew = list(norm = NULL, ged = NULL, std = NULL, snorm = 0.9, 
        sged = 0.9, sstd = 0.9)
    shape = list(norm = NULL, ged = 2, std = 4, snorm = NULL, 
        sged = 2, sstd = 4)
    
  #default parameters for garch model  
    control = list(omega = 1e-06, alpha = 0.1, gamma = NULL, 
        beta = 0.8, mu = NULL, ar = NULL, ma = NULL, delta = 2, 
        skew = skew[[cond.dist]], shape = shape[[cond.dist]])
    control[names(model)] <- model
    model <- control
  
  # obtaining ARIMA and GARCH order implied by function arguments   
    if (sum(c(model$alpha, model$beta)) > 1) 
        warnings("sum(alpha)+sum(beta)>1")
    order.ar = length(model$ar)
    order.ma = length(model$ma)
    order.alpha = length(model$alpha)
    if (sum(model$beta) == 0) {
        order.beta = 0
    }
    else {
        order.beta = length(model$beta)
    }
    
 # Getting arma(p,q)   
    if (order.ar == 0 && order.ma == 0) {
        formula.mean = ""
    }
    if (order.ar > 0 && order.ma == 0) {
        formula.mean = paste("ar(", as.character(order.ar), 
            ")", sep = "")
    }
    if (order.ar == 0 && order.ma > 0) {
        formula.mean = paste("ma(", as.character(order.ma), 
            ")", sep = "")
    }
    if (order.ar > 0 && order.ma > 0) {
        formula.mean = paste("arma(", as.character(order.ar), 
            ", ", as.character(order.ma), ")", sep = "")
    }
  # Getting garch(p,q)    
    formula.var = "garch"
    if (order.beta == 0) 
        formula.var = "arch"
    if (!is.null(model$gamma) != 0) 
        formula.var = "aparch"
    if (model$delta != 2) 
        formula.var = "aparch"
    if (order.beta == 0) {
        formula.var = paste(formula.var, "(", as.character(order.alpha), 
            ")", sep = "")
    }
    else {
        formula.var = paste(formula.var, "(", as.character(order.alpha), 
            ", ", as.character(order.beta), ")", 
            sep = "")
    }
    
  #Not sure about as.formula
    if (formula.mean == "") {
        formula = as.formula(paste("~", formula.var))
    }
    else {
        formula = as.formula(paste("~", formula.mean, "+", 
            formula.var))
    }
  
  #Setting null argumaents to zero  
    if (is.null(model$mu)) 
        model$mu = 0
    if (is.null(model$ar)) 
        model$ar = 0
    if (is.null(model$ma)) 
        model$ma = 0
    if (is.null(model$gamma)) 
        model$gamma = rep(0, times = order.alpha)
    
  # setting seed 
    if (is.null(rseed)) {
        rseed = 0
    }
    else {
        set.seed(rseed)
    }
    
  # deciding where to start for presample provided and not provided
    order.max = max(order.ar, order.ma, order.alpha, order.beta)
    iterate = TRUE
    if (!is.matrix(presample)) {
        if (is.null(presample)) {
            iterate = FALSE    #if presample is not a matrix and not NULL
            n.start = order.max
        }
        else {
            n.start = presample  
        }
    # z represents the first innovation = max lag  i.e this code generates a preamble if not provided 
        z = rnorm(n = n.start)    #innovations
        h = rep(model$omega/(1 - sum(model$alpha) - sum(model$beta)), 
            times = n.start)    #sd's
        y = rep(model$mu/(1 - sum(model$ar)), times = n.start)  #garch simulations
    }
    else {
        z = presample[, 1]
        h = presample[, 2]
        y = presample[, 3]
    }
    presample = cbind(z, h, y)
  
  #creating preamble data
    if (iterate) {  #iterate is TRUE if presample matrix is provided
        n.iterate = length(z) - order.max
        deltainv = 1/model$delta
        for (i in n.iterate:1) {
            h[i] = model$omega + sum(model$alpha * (abs(abs(y[i + 
                (1:order.alpha)]) - model$gamma * y[i + (1:order.alpha)])^model$delta)) + 
                sum(model$beta * h[i + (1:order.beta)])
            y[i] = model$mu + sum(model$ar * y[i + (1:order.ar)]) + 
                sum(model$ma * (h[i + (1:order.ma)]^deltainv)) + 
                h[i]^deltainv * z[i]
        }
    }
    new("fGARCHSPEC", call = match.call(), formula = formula, 
        model = list(omega = model$omega, alpha = model$alpha, 
            gamma = model$gamma, beta = model$beta, mu = model$mu, 
            ar = model$ar, ma = model$ma, delta = model$delta, 
            skew = model$skew, shape = model$shape), presample = as.matrix(presample), 
        distribution = as.character(cond.dist), rseed = as.numeric(rseed))
}


# Looking at garchSim
fGarch::garchSim(spec = garch)
function (spec = garchSpec(), n = 100, n.start = 100, extended = FALSE) 
{
    stopifnot(class(spec) == "fGARCHSPEC")
    model = spec@model  #list of model parameters
    if (spec@rseed != 0) 
        set.seed(spec@rseed)  #setting seed for RNG
    n = n + n.start
    
  #  will not need this, need to add my generated innovations
    if (spec@distribution == "norm") 
        z = rnorm(n)
    if (spec@distribution == "ged") 
        z = rged(n, nu = model$shape)
    if (spec@distribution == "std") 
        z = rstd(n, nu = model$shape)
    if (spec@distribution == "snorm") 
        z = rsnorm(n, xi = model$skew)
    if (spec@distribution == "sged") 
        z = rsged(n, nu = model$shape, xi = model$skew)
    if (spec@distribution == "sstd") 
        z = rsstd(n, nu = model$shape, xi = model$skew)
    delta = model$delta
    
  #Not sure how to work with the presample
    z = c(rev(spec@presample[, 1]), z)   #2nd column is the random innovation
    h = c(rev(spec@presample[, 2]), rep(NA, times = n))
    y = c(rev(spec@presample[, 3]), rep(NA, times = n))
    m = length(spec@presample[, 1])
    names(z) = names(h) = names(y) = NULL  #setting names to NULL
    
  #obtaining parameters and lag orders from model object
    mu = model$mu 
    ar = model$ar
    ma = model$ma
    omega = model$omega
    alpha = model$alpha
    gamma = model$gamma
    beta = model$beta
    deltainv = 1/delta
    order.ar = length(ar)
    order.ma = length(ma)
    order.alpha = length(alpha)
    order.beta = length(beta)
    eps = h^deltainv * z
    
    for (i in (m + 1):(n + m)) {
        h[i] = omega + sum(alpha * (abs(eps[i - (1:order.alpha)]) - 
            gamma * (eps[i - (1:order.alpha)]))^delta) + sum(beta * 
            h[i - (1:order.beta)])  #need to know what gets filled into h
        
        eps[i] = h[i]^deltainv * z[i]
        y[i] = mu + sum(ar * y[i - (1:order.ar)]) + sum(ma * 
            eps[i - (1:order.ma)]) + eps[i]
    }
    data = cbind(z = z[(m + 1):(n + m)], sigma = h[(m + 1):(n + 
        m)]^deltainv, y = y[(m + 1):(n + m)])
    
    rownames(data) = as.character(1:n)
    data = data[-(1:n.start), ]   #removing the burn in periods
    
    #getting start date
    from <- timeDate(format(Sys.time(), format = "%Y-%m-%d")) - 
        NROW(data) * 24 * 3600
    charvec <- timeSequence(from = from, length.out = NROW(data))
    
    # putting simulated data and time variable together
    ans <- timeSeries(data = data[, c(3, 2, 1)], charvec = charvec)
    colnames(ans) <- c("garch", "sigma", "eps")
    
    ans <- if (extended)   #is there a need to have extended output?
        ans
    else ans[, "garch"]
    attr(ans, "control") <- list(garchSpec = spec)
    ans
}

garchSim(garch, n = 252, extended = TRUE) %>% plot()
```

## My edit of garch sim

```{r}
#covar matrix
corr <- gcVar(N = 50, Clusters = "non-overlapping", Num_Clusters = 2)
#innovations
inn <- hycop(corr, left_cop_weight = 0.5, marginal_dist = "norm")

# Looking at garchSim
fGarch::garchSim(spec = garch)

sim.mv <- function (model = list(), n = 100, n.start = 100, presample = NULL, set_seed = NULL, extended = FALSE) 
{
   #default parameters for garch model  
    control = list(omega = 1e-06, alpha = 0.1, gamma = NULL, 
        beta = 0.8, mu = 0, ar = NULL, ma = NULL, delta = 2, 
        skew = skew[[cond.dist]], shape = shape[[cond.dist]])
    control[names(model)] <- model
    model <- control   #list of model parameters
    
    n = n + n.start
  
  # obtaining ARIMA(p,q) and GARCH(q,p) order implied by function arguments   
    if (sum(c(model$alpha, model$beta)) > 1) 
        warnings("sum(alpha)+sum(beta)>1")
    order.ar = length(model$ar)
    order.ma = length(model$ma)
    order.alpha = length(model$alpha)
    if (sum(model$beta) == 0) {
        order.beta = 0
    }else {
        order.beta = length(model$beta)
    }
    
  # Generating presample for when it is and is not provided
    order.max = max(order.ar, order.ma, order.alpha, order.beta)
    iterate = TRUE
    if (!is.matrix(presample)) {       #why is.matrix and is.null???
        if (is.null(presample)) {
            iterate = FALSE   #if presample is NULL
            n.start = order.max
        }else {
            n.start = presample #if presample is not matrix an not Null
        }
    # z represents the first innovation = max lag  i.e this code generates a presample if not provided 
        z = rnorm(n = n.start)    #innovations in presample
        h = rep(model$omega/(1 - sum(model$alpha) - sum(model$beta)), 
            times = n.start)    #sd's in presample
        y = rep(model$mu/(1 - sum(model$ar)), times = n.start)  #garch simulations in presample
    }else {
        z = presample[, 1]
        h = presample[, 2]
        y = presample[, 3]
    }
    presample = cbind(z, h, y)
    
  # creating innovations object (z); will insert copula rng later  
    set.seed(set_seed)  #setting seed for RNG
    z <- rnorm(n, mean = 0.01, sd = 0.5)
  
  #generating innovations vector
    z = c(rev(presample[, 1]), z)   #adding random innovations to those in presample
    h = c(rev(presample[, 2]), rep(NA, times = n)) #sd's
    y = c(rev(presample[, 3]), rep(NA, times = n)) #simulated garch process
    m = length(presample[, 1])
    names(z) = names(h) = names(y) = NULL  #setting names to NULL
    
  #obtaining parameters and lag orders from model object
    mu = model$mu 
    ar = model$ar
    ma = model$ma
    omega = model$omega
    alpha = model$alpha
    gamma = model$gamma
    beta = model$beta
    delta = model$delta
    deltainv = 1/delta
    order.ar = length(ar)
    order.ma = length(ma)
    order.alpha = length(alpha)
    order.beta = length(beta)
    eps = h^deltainv * z
    
  #simulating data  
    for (i in (m + 1):(n + m)) {
        h[i] = omega + sum(alpha * (abs(eps[i - (1:order.alpha)]) - 
            gamma * (eps[i - (1:order.alpha)]))^delta) + sum(beta * 
            h[i - (1:order.beta)])  #need to know what gets filled into h
        
        eps[i] = h[i]^deltainv * z[i]
        y[i] = mu + sum(ar * y[i - (1:order.ar)]) + sum(ma * 
            eps[i - (1:order.ma)]) + eps[i]
    }
    data = cbind(z = z[(m + 1):(n + m)], sigma = h[(m + 1):(n + 
        m)]^deltainv, y = y[(m + 1):(n + m)])
    
    rownames(data) = as.character(1:n)
    data = data[-(1:n.start), ]   #removing the burn in periods
    
    #getting start date
    from <- timeDate(format(Sys.time(), format = "%Y-%m-%d")) - 
        NROW(data) * 24 * 3600
    charvec <- timeSequence(from = from, length.out = NROW(data))
    
    # putting simulated data and time variable together
    ans <- timeSeries(data = data[, c(3, 2, 1)], charvec = charvec)
    colnames(ans) <- c("garch", "sigma", "eps")
    
    ans <- if (extended)   #is there a need to have extended output?
        ans
    else ans[, "garch"]
    attr(ans, "control") <- list(garchSpec = spec)
    ans
}


```

My go at writing a GARCHSIM function

```{r}
'

corr <- gcVar(N = 4, Clusters = "non-overlapping", Num_Clusters = 2)
inno <- hycop(corr, left_cop_weight = 0.5, T = 251, marginal_dist = "t")
model <- list(ar = 0.1, alpha = 0.1, beta = 0.75, gamma = 0.1)

my.sim.mv <- function(model= list(), innovations = NULL, presample = NULL, n.start = 100){
  
  if(is.null(innovations)==TRUE)stop("Please provide valid innovations argument")
  n = length(innovations) + n.start
  
  #default parameters for garch model  
    default = list(omega = 1e-06, 
                   alpha = 0.1,
                   gamma = NULL, 
                   beta = 0.8, 
                   mu = 0,   #changed form NULL to 0
                   ar = NULL, 
                   ma = NULL, 
                   delta = 2)
    
    default[names(model)] <- model
    model <- default   #list of model parameters
  
  #Generating Presample
    

    
  #obtaining parameters and lag orders from model object
    mu = model$mu 
    ar = model$ar
    ma = model$ma
    omega = model$omega
    alpha = model$alpha
    gamma = model$gamma
    beta = model$beta
    delta = model$delta
    deltainv = 1/delta
    order.ar = length(ar)
    order.ma = length(ma)
    order.alpha = length(alpha)
    order.beta = length(beta)
    eps = h^deltainv * z
    

  
}

#my.sim.mv(model = model, innovations = inno)
'

```


